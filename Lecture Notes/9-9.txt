Big O notation:
	- gives you an approximate sense of how long something is
	- order of magnitude analysis
	- Log function < polynomial < exponential
	- log bases don't matter
	- only the largest terms of a polynomial matter
	- big O gives you the upper bound of the function that describes the algorithm
	- How to count the number of operations:
		- must be reasonable operations (no massive numbers in elementary arithmetic)
		- Loops are critical
		Ex:
			sum = 0
			for (int j=1; j<n; j++)
				sum = sum + j
		Number of operations is constant - not dependent upon n
		will operate ~ n times

		Ex:
			for (int j=0; j<n; j++)
				for (int k=0; k<n; k++)
					println (j+k)
			number of operations based on the nested loops, i.e. n^2

		Ex:
			adding two matrices ( O(n^2) )
			while (n>1), n = n/2; ( O(n) )
			linear search ( O(n) )
			binary search ( O(lg(n)) )
	- If worstTime(n) is _____, we will say 
	- “worstTime(n) is ______.”
	- O(1) ... constant
	- O(log n) ... logarithmic in n
	- O(n) ... linear in n
	- O(n2) ... quadratic in n
	- O(2n) ... exponential in n

Sorting:

	Insertion Sort:
		for i ← 2 to n do {
		/* put A[i] in correct spot */
			x ← A[i]; j ← i-1
			while (j > 0) AND (x< A[j]) {
				A[j+1] ← A[j] 
				j ← j-1
			}
			A[j+1] ← x 
		}
	worst case = O(n^2)
	best case = O(n)
	Average case = somewhere between n and n^2

	Omega notation: = Ω() lower bound

	Theta notation: = Θ() used when O() = Ω()

	Merge sort

	Merge Algorithm:
		Input: sorted arrays A, B
		Output: combined sorted array C
	Time analysis of merge sort
	Merge Sort:
		Assume n is a power of 2
			merge_sort(A[n]) {
				if A[].length > 2 {
					k ← A[].length/2
					L[] ← A[1..k]
					R[] ← A[k+1..n]
					merge_sort(L)
					merge_sort(R)
				}
				else {
					merge L,R into A
				}
			}
